{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, TFAutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "from transformers import Trainer, TrainingArguments, DefaultDataCollator\n",
    "from datasets import Dataset\n",
    "from typing import Dict, List, Optional\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class BrandSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize all transformer models with TensorFlow backend\"\"\"\n",
    "        # Emotion detection model\n",
    "        self.emotion_model = pipeline(\n",
    "            'text-classification',\n",
    "            model='SamLowe/roberta-base-go_emotions',\n",
    "            return_all_scores=True,\n",
    "            framework=\"tf\"\n",
    "        )\n",
    "        \n",
    "        # Sarcasm detection model\n",
    "        self.sarcasm_tokenizer = AutoTokenizer.from_pretrained(\"MohamedGalal/marbert-sarcasm-detector\")\n",
    "        self.sarcasm_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "            \"MohamedGalal/marbert-sarcasm-detector\"\n",
    "        )\n",
    "\n",
    "        # Sentiment analysis model\n",
    "        self.sentiment_model = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "            framework=\"tf\"\n",
    "        )\n",
    "\n",
    "        # Brand perception model\n",
    "        self.perception_model = pipeline(\n",
    "            \"zero-shot-classification\",\n",
    "            model=\"facebook/bart-large-mnli\",\n",
    "            framework=\"tf\"\n",
    "        )\n",
    "        \n",
    "        # Configure device (GPU if available)\n",
    "        self.device = \"cuda\" if tf.config.list_physical_devices('GPU') else \"cpu\"\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "\n",
    "    def _preprocess_emotion_data(self, texts: List[str], labels: List[Dict[str, float]]) -> Dataset:\n",
    "        \"\"\"Convert emotion data to HuggingFace Dataset format\"\"\"\n",
    "        data = {\"text\": texts, \"labels\": labels}\n",
    "        return Dataset.from_dict(data)\n",
    "\n",
    "    def fine_tune_emotion_model(self, train_texts: List[str], train_labels: List[Dict[str, float]], \n",
    "                               val_texts: Optional[List[str]] = None, val_labels: Optional[List[Dict[str, float]]] = None,\n",
    "                               epochs: int = 3, batch_size: int = 8):\n",
    "        \"\"\"\n",
    "        Fine-tune the emotion detection model\n",
    "        \n",
    "        Args:\n",
    "            train_texts: List of training texts\n",
    "            train_labels: List of dictionaries with emotion scores\n",
    "            val_texts: Optional validation texts\n",
    "            val_labels: Optional validation labels\n",
    "            epochs: Number of training epochs\n",
    "            batch_size: Batch size for training\n",
    "        \"\"\"\n",
    "        logger.info(\"Fine-tuning emotion model...\")\n",
    "        \n",
    "        # Convert labels to the format expected by the model\n",
    "        emotion_labels = list(train_labels[0].keys())\n",
    "        label2id = {label: idx for idx, label in enumerate(emotion_labels)}\n",
    "        \n",
    "        # Convert training data\n",
    "        train_dataset = self._preprocess_emotion_data(train_texts, train_labels)\n",
    "        \n",
    "        # Tokenize data\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "        \n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "        \n",
    "        tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "        \n",
    "        # Prepare model for fine-tuning\n",
    "        config = AutoConfig.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "        model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "            \"SamLowe/roberta-base-go_emotions\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        # Training setup would go here (simplified for example)\n",
    "        # In practice, you'd need to implement proper training loop\n",
    "        logger.info(\"Emotion model fine-tuning setup complete (implementation needed)\")\n",
    "\n",
    "    def detect_emotions(self, text: str) -> Dict:\n",
    "        \"\"\"Detect emotions in text with confidence scores\"\"\"\n",
    "        results = self.emotion_model(text)[0]\n",
    "        return {item['label']: item['score'] for item in results}\n",
    "    \n",
    "    def detect_sarcasm(self, text: str) -> Dict:\n",
    "        \"\"\"Detect sarcasm with confidence scores\"\"\"\n",
    "        inputs = self.sarcasm_tokenizer(text, return_tensors=\"tf\", truncation=True)\n",
    "        outputs = self.sarcasm_model(**inputs)\n",
    "        probs = tf.nn.softmax(outputs.logits, axis=1)\n",
    "        return {\n",
    "            'sarcastic': float(probs[0][1]),\n",
    "            'literal': float(probs[0][0])\n",
    "        }\n",
    "    \n",
    "    def analyze_sentiment(self, text: str) -> Dict:\n",
    "        \"\"\"Analyze sentiment with confidence score\"\"\"\n",
    "        result = self.sentiment_model(text)[0]\n",
    "        return {'label': result['label'], 'score': result['score']}\n",
    "    \n",
    "    def assess_brand_perception(self, text: str, brand_name: str) -> Dict:\n",
    "        \"\"\"Assess brand perception across multiple dimensions\"\"\"\n",
    "        candidate_labels = [\n",
    "            \"positive\", \"negative\", \"trustworthy\", \n",
    "            \"innovative\", \"expensive\", \"good value\",\n",
    "            \"reliable\", \"poor quality\", \"luxury\",\n",
    "            \"outdated\", \"trendy\", \"ethical\"\n",
    "        ]\n",
    "        result = self.perception_model(text, candidate_labels, multi_label=True)\n",
    "        return {\n",
    "            'brand': brand_name,\n",
    "            'perception_scores': dict(zip(result['labels'], result['scores']))\n",
    "        }\n",
    "    \n",
    "    def calculate_composite_sentiment(self, analysis: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Calculate composite sentiment score (0-1 scale) combining:\n",
    "        - Emotion analysis\n",
    "        - Sarcasm detection\n",
    "        - Sentiment analysis\n",
    "        - Brand perception\n",
    "        \"\"\"\n",
    "        # Positive emotions contribute positively\n",
    "        positive_emotions = ['admiration', 'amusement', 'approval', 'caring', 'desire',\n",
    "                            'excitement', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'relief']\n",
    "        emotion_score = sum(analysis['emotions'].get(emotion, 0) for emotion in positive_emotions)\n",
    "        \n",
    "        # Negative emotions contribute negatively\n",
    "        negative_emotions = ['anger', 'annoyance', 'disappointment', 'disapproval', \n",
    "                           'disgust', 'embarrassment', 'fear', 'grief', 'nervousness',\n",
    "                           'remorse', 'sadness']\n",
    "        emotion_score -= sum(analysis['emotions'].get(emotion, 0) for emotion in negative_emotions)\n",
    "        \n",
    "        # Normalize emotion score (-1 to 1 range)\n",
    "        emotion_score = emotion_score / len(analysis['emotions'])\n",
    "        \n",
    "        # Adjust for sarcasm (sarcastic comments often flip sentiment)\n",
    "        sarcasm_adjustment = 1 - (2 * analysis['sarcasm']['sarcastic'])\n",
    "        \n",
    "        # Get sentiment score (-1 for negative, 0 for neutral, 1 for positive)\n",
    "        sentiment_map = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "        sentiment_score = sentiment_map.get(analysis['sentiment']['label'].lower(), 0) * analysis['sentiment']['score']\n",
    "        \n",
    "        # Get brand perception adjustment\n",
    "        perception_score = (\n",
    "            analysis['brand_perception']['perception_scores'].get('positive', 0) -\n",
    "            analysis['brand_perception']['perception_scores'].get('negative', 0)\n",
    "        )\n",
    "        \n",
    "        # Combine scores with weights\n",
    "        composite_score = (\n",
    "            0.4 * emotion_score + \n",
    "            0.3 * sentiment_score * sarcasm_adjustment + \n",
    "            0.3 * perception_score\n",
    "        )\n",
    "        \n",
    "        # Normalize to 0-1 range\n",
    "        return (composite_score + 1) / 2\n",
    "    \n",
    "    def generate_perception_wordcloud(self, perception_scores: Dict[str, float], brand_name: str):\n",
    "        \"\"\"\n",
    "        Generate a word cloud visualization of brand perception\n",
    "        \n",
    "        Args:\n",
    "            perception_scores: Dictionary of perception scores from assess_brand_perception\n",
    "            brand_name: Brand name for title\n",
    "            \n",
    "        Returns:\n",
    "            matplotlib Figure object\n",
    "        \"\"\"\n",
    "        # Create word frequencies dictionary\n",
    "        word_freq = {k: v * 100 for k, v in perception_scores.items()}\n",
    "        \n",
    "        # Generate word cloud\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.set_title(f\"Brand Perception: {brand_name}\", fontsize=15)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def full_analysis(self, text: str, brand_name: str, generate_visualization: bool = True) -> Dict:\n",
    "        \"\"\"\n",
    "        Perform complete sentiment and brand analysis\n",
    "        \n",
    "        Args:\n",
    "            text: Text to analyze\n",
    "            brand_name: Brand name for perception analysis\n",
    "            generate_visualization: Whether to generate word cloud\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with complete analysis results\n",
    "        \"\"\"\n",
    "        analysis = {\n",
    "            \"text\": text,\n",
    "            \"emotions\": self.detect_emotions(text),\n",
    "            \"sarcasm\": self.detect_sarcasm(text),\n",
    "            \"sentiment\": self.analyze_sentiment(text),\n",
    "            \"brand_perception\": self.assess_brand_perception(text, brand_name)\n",
    "        }\n",
    "        \n",
    "        # Calculate composite score\n",
    "        analysis[\"composite_sentiment_score\"] = self.calculate_composite_sentiment(analysis)\n",
    "        \n",
    "        # Generate visualization if requested\n",
    "        if generate_visualization:\n",
    "            analysis[\"perception_wordcloud\"] = self.generate_perception_wordcloud(\n",
    "                analysis[\"brand_perception\"][\"perception_scores\"],\n",
    "                brand_name\n",
    "            )\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = BrandSentimentAnalyzer()\n",
    "    \n",
    "    # Example text and brand\n",
    "    sample_text = \"I love how this brand always delivers quality products, said no one ever!\"\n",
    "    brand = \"ExampleCorp\"\n",
    "    \n",
    "    # Perform full analysis\n",
    "    results = analyzer.full_analysis(sample_text, brand)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Composite Sentiment Score: {results['composite_sentiment_score']:.2f}\")\n",
    "    print(\"\\nBrand Perception Scores:\")\n",
    "    for label, score in results[\"brand_perception\"][\"perception_scores\"].items():\n",
    "        print(f\"{label}: {score:.2f}\")\n",
    "    \n",
    "    # Show word cloud\n",
    "    if \"perception_wordcloud\" in results:\n",
    "        results[\"perception_wordcloud\"].show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
